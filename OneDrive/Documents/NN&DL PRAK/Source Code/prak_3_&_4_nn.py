# -*- coding: utf-8 -*-
"""Prak 3 & 4 NN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l_qMX6cQN4EuZIQzS4_1QLQabBxMtHUV
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt

# Memuat dataset
data = pd.read_csv('train.csv')

# Memeriksa informasi dan nilai yang hilang
print(data.info())
print(data.isnull().sum())

# Salin data asli sebelum imputasi
data_nn = data.copy()

# Mengisi nilai yang hilang
imp = SimpleImputer(strategy="most_frequent")
data[['Age', 'Embarked']] = imp.fit_transform(data[['Age', 'Embarked']])

# Mengonversi kolom kategorikal menjadi numerik
data['Sex'] = LabelEncoder().fit_transform(data['Sex'])
data = pd.get_dummies(data, columns=['Embarked'], drop_first=True)

# Memisahkan fitur dan target
X = data.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])  # Menghapus kolom yang tidak digunakan
y = data['Survived']  # Kolom target

# Membagi data menjadi data latih dan uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Membagi data latih menjadi data latih dan validasi (80% training, 20% validation dari data training)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)

# Normalisasi fitur
scaler = StandardScaler()
scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
X_val = scaler.transform(X_val)

# Membuat model MLPClassifier
mlp = MLPClassifier(hidden_layer_sizes=(5, 5), max_iter=1000)

# Lists to store the training and validation loss
train_loss = []
val_loss = []

# Melatih model sambil mencatat loss training dan validation
for epoch in range(1000):  # 1000 epochs
    mlp.partial_fit(X_train, y_train, classes=[0, 1])  # Train on batch

    # Compute and store the loss for this epoch
    train_loss.append(mlp.loss_)

    # Calculate validation loss using the current model
    val_predictions = mlp.predict_proba(X_val)
    val_loss_epoch = - (y_val * np.log(val_predictions[:, 1]) + (1 - y_val) * np.log(1 - val_predictions[:, 1])).mean()
    val_loss.append(val_loss_epoch)

# Melakukan prediksi pada data uji
predictions = mlp.predict(X_test)

# Menampilkan laporan klasifikasi
print(classification_report(y_test, predictions))

# Menampilkan akurasi dalam persen
accuracy_percent = accuracy_score(y_test, predictions) * 100
print('Accuracy: {:.2f}%'.format(accuracy_percent))

# Menampilkan confusion matrix
print(confusion_matrix(y_test, predictions))

# Plotting training vs validation loss
plt.plot(train_loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.show()import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt

# Memuat dataset
data = pd.read_csv('train.csv')

# Memeriksa informasi dan nilai yang hilang
print(data.info())
print(data.isnull().sum())

# Salin data asli sebelum imputasi
data_nn = data.copy()

# Mengisi nilai yang hilang
imp = SimpleImputer(strategy="most_frequent")
data[['Age', 'Embarked']] = imp.fit_transform(data[['Age', 'Embarked']])

# Mengonversi kolom kategorikal menjadi numerik
data['Sex'] = LabelEncoder().fit_transform(data['Sex'])
data = pd.get_dummies(data, columns=['Embarked'], drop_first=True)

# Memisahkan fitur dan target
X = data.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])  # Menghapus kolom yang tidak digunakan
y = data['Survived']  # Kolom target

# Membagi data menjadi data latih dan uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Membagi data latih menjadi data latih dan validasi (80% training, 20% validation dari data training)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)

# Normalisasi fitur
scaler = StandardScaler()
scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
X_val = scaler.transform(X_val)

# Membuat model MLPClassifier
mlp = MLPClassifier(hidden_layer_sizes=(5, 5), max_iter=1000)

# Lists to store the training and validation loss
train_loss = []
val_loss = []

# Melatih model sambil mencatat loss training dan validation
for epoch in range(1000):  # 1000 epochs
    mlp.partial_fit(X_train, y_train, classes=[0, 1])  # Train on batch

    # Compute and store the loss for this epoch
    train_loss.append(mlp.loss_)

    # Calculate validation loss using the current model
    val_predictions = mlp.predict_proba(X_val)
    val_loss_epoch = - (y_val * np.log(val_predictions[:, 1]) + (1 - y_val) * np.log(1 - val_predictions[:, 1])).mean()
    val_loss.append(val_loss_epoch)

# Melakukan prediksi pada data uji
predictions = mlp.predict(X_test)

# Menampilkan laporan klasifikasi
print(classification_report(y_test, predictions))

# Menampilkan akurasi dalam persen
accuracy_percent = accuracy_score(y_test, predictions) * 100
print('Accuracy: {:.2f}%'.format(accuracy_percent))

# Menampilkan confusion matrix
print(confusion_matrix(y_test, predictions))

# Plotting training vs validation loss
plt.plot(train_loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.show()import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt

# Memuat dataset
data = pd.read_csv('train.csv')

# Memeriksa informasi dan nilai yang hilang
print(data.info())
print(data.isnull().sum())

# Salin data asli sebelum imputasi
data_nn = data.copy()

# Mengisi nilai yang hilang
imp = SimpleImputer(strategy="most_frequent")
data[['Age', 'Embarked']] = imp.fit_transform(data[['Age', 'Embarked']])

# Mengonversi kolom kategorikal menjadi numerik
data['Sex'] = LabelEncoder().fit_transform(data['Sex'])
data = pd.get_dummies(data, columns=['Embarked'], drop_first=True)

# Memisahkan fitur dan target
X = data.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])  # Menghapus kolom yang tidak digunakan
y = data['Survived']  # Kolom target

# Membagi data menjadi data latih dan uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Membagi data latih menjadi data latih dan validasi (80% training, 20% validation dari data training)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)

# Normalisasi fitur
scaler = StandardScaler()
scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
X_val = scaler.transform(X_val)

# Membuat model MLPClassifier
mlp = MLPClassifier(hidden_layer_sizes=(5, 5), max_iter=1000)

# Lists to store the training and validation loss
train_loss = []
val_loss = []

# Melatih model sambil mencatat loss training dan validation
for epoch in range(1000):  # 1000 epochs
    mlp.partial_fit(X_train, y_train, classes=[0, 1])  # Train on batch

    # Compute and store the loss for this epoch
    train_loss.append(mlp.loss_)

    # Calculate validation loss using the current model
    val_predictions = mlp.predict_proba(X_val)
    val_loss_epoch = - (y_val * np.log(val_predictions[:, 1]) + (1 - y_val) * np.log(1 - val_predictions[:, 1])).mean()
    val_loss.append(val_loss_epoch)

# Melakukan prediksi pada data uji
predictions = mlp.predict(X_test)

# Menampilkan laporan klasifikasi
print(classification_report(y_test, predictions))

# Menampilkan akurasi dalam persen
accuracy_percent = accuracy_score(y_test, predictions) * 100
print('Accuracy: {:.2f}%'.format(accuracy_percent))

# Menampilkan confusion matrix
print(confusion_matrix(y_test, predictions))

# Plotting training vs validation loss
plt.plot(train_loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.show()import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt

# Memuat dataset
data = pd.read_csv('train.csv')

# Memeriksa informasi dan nilai yang hilang
print(data.info())
print(data.isnull().sum())

# Salin data asli sebelum imputasi
data_nn = data.copy()

# Mengisi nilai yang hilang
imp = SimpleImputer(strategy="most_frequent")
data[['Age', 'Embarked']] = imp.fit_transform(data[['Age', 'Embarked']])

# Mengonversi kolom kategorikal menjadi numerik
data['Sex'] = LabelEncoder().fit_transform(data['Sex'])
data = pd.get_dummies(data, columns=['Embarked'], drop_first=True)

# Memisahkan fitur dan target
X = data.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])  # Menghapus kolom yang tidak digunakan
y = data['Survived']  # Kolom target

# Membagi data menjadi data latih dan uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Membagi data latih menjadi data latih dan validasi (80% training, 20% validation dari data training)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)

# Normalisasi fitur
scaler = StandardScaler()
scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
X_val = scaler.transform(X_val)

# Membuat model MLPClassifier
mlp = MLPClassifier(hidden_layer_sizes=(5, 5), max_iter=1000)

# Lists to store the training and validation loss
train_loss = []
val_loss = []

# Melatih model sambil mencatat loss training dan validation
for epoch in range(1000):  # 1000 epochs
    mlp.partial_fit(X_train, y_train, classes=[0, 1])  # Train on batch

    # Compute and store the loss for this epoch
    train_loss.append(mlp.loss_)

    # Calculate validation loss using the current model
    val_predictions = mlp.predict_proba(X_val)
    val_loss_epoch = - (y_val * np.log(val_predictions[:, 1]) + (1 - y_val) * np.log(1 - val_predictions[:, 1])).mean()
    val_loss.append(val_loss_epoch)

# Melakukan prediksi pada data uji
predictions = mlp.predict(X_test)

# Menampilkan laporan klasifikasi
print(classification_report(y_test, predictions))

# Menampilkan akurasi dalam persen
accuracy_percent = accuracy_score(y_test, predictions) * 100
print('Accuracy: {:.2f}%'.format(accuracy_percent))

# Menampilkan confusion matrix
print(confusion_matrix(y_test, predictions))

# Plotting training vs validation loss
plt.plot(train_loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.show()import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt

# Memuat dataset
data = pd.read_csv('train.csv')

# Memeriksa informasi dan nilai yang hilang
print(data.info())
print(data.isnull().sum())

# Salin data asli sebelum imputasi
data_nn = data.copy()

# Mengisi nilai yang hilang
imp = SimpleImputer(strategy="most_frequent")
data[['Age', 'Embarked']] = imp.fit_transform(data[['Age', 'Embarked']])

# Mengonversi kolom kategorikal menjadi numerik
data['Sex'] = LabelEncoder().fit_transform(data['Sex'])
data = pd.get_dummies(data, columns=['Embarked'], drop_first=True)

# Memisahkan fitur dan target
X = data.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])  # Menghapus kolom yang tidak digunakan
y = data['Survived']  # Kolom target

# Membagi data menjadi data latih dan uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Membagi data latih menjadi data latih dan validasi (80% training, 20% validation dari data training)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)

# Normalisasi fitur
scaler = StandardScaler()
scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
X_val = scaler.transform(X_val)

# Membuat model MLPClassifier
mlp = MLPClassifier(hidden_layer_sizes=(5, 5), max_iter=1000)

# Lists to store the training and validation loss
train_loss = []
val_loss = []

# Melatih model sambil mencatat loss training dan validation
for epoch in range(1000):  # 1000 epochs
    mlp.partial_fit(X_train, y_train, classes=[0, 1])  # Train on batch

    # Compute and store the loss for this epoch
    train_loss.append(mlp.loss_)

    # Calculate validation loss using the current model
    val_predictions = mlp.predict_proba(X_val)
    val_loss_epoch = - (y_val * np.log(val_predictions[:, 1]) + (1 - y_val) * np.log(1 - val_predictions[:, 1])).mean()
    val_loss.append(val_loss_epoch)

# Melakukan prediksi pada data uji
predictions = mlp.predict(X_test)

# Menampilkan laporan klasifikasi
print(classification_report(y_test, predictions))

# Menampilkan akurasi dalam persen
accuracy_percent = accuracy_score(y_test, predictions) * 100
print('Accuracy: {:.2f}%'.format(accuracy_percent))

# Menampilkan confusion matrix
print(confusion_matrix(y_test, predictions))

# Plotting training vs validation loss
plt.plot(train_loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
import numpy as np

# Memuat dataset
data = pd.read_csv('train.csv')

# Memeriksa informasi dan nilai yang hilang
print(data.info())
print(data.isnull().sum())

# Salin data asli sebelum imputasi
data_nn = data.copy()

# Mengisi nilai yang hilang
imp = SimpleImputer(strategy="most_frequent")
data[['Age', 'Embarked']] = imp.fit_transform(data[['Age', 'Embarked']])

# Mengonversi kolom kategorikal menjadi numerik
data['Sex'] = LabelEncoder().fit_transform(data['Sex'])
data = pd.get_dummies(data, columns=['Embarked'], drop_first=True)

# Memisahkan fitur dan target
X = data.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])  # Menghapus kolom yang tidak digunakan
y = data['Survived']  # Kolom target

# Membagi data menjadi data latih dan uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Membagi data latih menjadi data latih dan validasi (80% training, 20% validation dari data training)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)

# Normalisasi fitur
scaler = StandardScaler()
scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
X_val = scaler.transform(X_val)

# Membuat model MLPClassifier dengan L2 Regularization
mlp = MLPClassifier(hidden_layer_sizes=(5, 5), max_iter=1000, alpha=0.01)

# Lists to store the training and validation loss
train_loss = []
val_loss = []

# Melatih model sambil mencatat loss training dan validation
patience = 50  # jumlah epoch untuk menunggu sebelum berhenti
best_val_loss = float('inf')
epochs_without_improvement = 0

for epoch in range(1000):
    mlp.partial_fit(X_train, y_train, classes=[0, 1])
    train_loss.append(mlp.loss_)

    # Menghitung loss validasi
    val_predictions = mlp.predict_proba(X_val)
    val_loss_epoch = - (y_val * np.log(val_predictions[:, 1]) + (1 - y_val) * np.log(1 - val_predictions[:, 1])).mean()
    val_loss.append(val_loss_epoch)

    # Mengecek untuk early stopping
    if val_loss_epoch < best_val_loss:
        best_val_loss = val_loss_epoch
        epochs_without_improvement = 0
    else:
        epochs_without_improvement += 1

    if epochs_without_improvement >= patience:
        print(f'Early stopping at epoch {epoch}')
        break

# Melakukan prediksi pada data uji
predictions = mlp.predict(X_test)

# Menampilkan laporan klasifikasi
print(classification_report(y_test, predictions))

# Menampilkan akurasi dalam persen
accuracy_percent = accuracy_score(y_test, predictions) * 100
print('Accuracy: {:.2f}%'.format(accuracy_percent))

# Menampilkan confusion matrix
print(confusion_matrix(y_test, predictions))

# Plotting training vs validation loss
plt.plot(train_loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.show()

# Import libraries yang diperlukan
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt

# Membagi dataset menjadi data latih dan uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Normalisasi fitur
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Membuat model MLPRegressor
mlp = MLPRegressor(hidden_layer_sizes=(10, 10, 10), max_iter=1, warm_start=True)

# List untuk menyimpan nilai loss dari training dan validation
train_loss = []
val_loss = []

# Melatih model per epoch dan melacak training & validation loss
for epoch in range(100):  # 100 epochs
    mlp.fit(X_train, y_train)

    # Hitung training loss
    train_loss.append(mlp.loss_)

    # Hitung validation loss
    predictions = mlp.predict(X_test)
    val_loss.append(mean_squared_error(y_test, predictions))

# Plot learning curve untuk training dan validation loss
plt.plot(train_loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Training and Validation Loss per Epoch')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# Setelah selesai training, tampilkan metrik
mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)
print("Mean Squared Error: {:.2f}".format(mse))
print("RÂ² Score: {:.2f}".format(r2))

# Jika ingin mengonversi prediksi ke binary (untuk confusion matrix & classification report)
predictions_binary = (predictions > 0.5).astype(int)

# Menampilkan confusion matrix dan classification report
print(confusion_matrix(y_test, predictions_binary))
print(classification_report(y_test, predictions_binary))